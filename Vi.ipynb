{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, f1_score, recall_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    Load events and subscribers data, drop unnecessary columns, and handle missing values.\n",
    "\n",
    "    Returns:\n",
    "    events_data (pd.DataFrame): DataFrame containing events data.\n",
    "    subscribers_data (pd.DataFrame): DataFrame containing subscribers data.\n",
    "    \"\"\"\n",
    "    events_data = pd.read_csv('data/events_data.csv')\n",
    "    subscribers_data = pd.read_csv('data/subscribers_data.csv')\n",
    "\n",
    "    # Handle missing values\n",
    "    events_data.fillna(0, inplace=True)\n",
    "    subscribers_data.fillna(0, inplace=True)\n",
    "\n",
    "    # Convert date fields to datetime format\n",
    "    events_data['dt'] = pd.to_datetime(events_data['dt'])\n",
    "    subscribers_data['effective_date'] = pd.to_datetime(subscribers_data['effective_date'])\n",
    "\n",
    "    # Sort data by date\n",
    "    events_data.sort_values(by='dt', inplace=True)\n",
    "    subscribers_data.sort_values(by='effective_date', inplace=True)\n",
    "\n",
    "    # Merge data\n",
    "    # Step 1: Drop rows not in subscribers_data\n",
    "    events_data = events_data[events_data['member_id'].isin(subscribers_data['member_id'])]\n",
    "\n",
    "    # Step 2: Keep only unique rows in subscribers_data\n",
    "    unique_subscribers_data = subscribers_data.drop_duplicates(subset='member_id')\n",
    "\n",
    "    # Step 3: Merge data to add 'gender', 'city', and 'age' columns\n",
    "    merged_data = pd.merge(events_data, unique_subscribers_data[['member_id', 'gender', 'city', 'age', 'effective_date']], on='member_id', how='left')\n",
    "\n",
    "    # Calculate age from effective_date to dt\n",
    "    merged_data['age'] = merged_data['age'] - ((merged_data['effective_date'] - merged_data['dt']).dt.days // 365)\n",
    "\n",
    "    default_age_value = 0\n",
    "    merged_data['age'] = merged_data['age'].apply(lambda x: x if x >= 0 else default_age_value)\n",
    "\n",
    "    merged_data.drop(columns=['effective_date'], inplace=True)\n",
    "\n",
    "    # Save to new csv\n",
    "    # merged_data.to_csv('updated_events_data.csv', index=False)\n",
    "\n",
    "    return merged_data, subscribers_data\n",
    "\n",
    "def filter_events_by_date(events_data, specific_date, duration):\n",
    "    \"\"\"\n",
    "    Filter events data based on a specific date and duration.\n",
    "\n",
    "    Args:\n",
    "    events_data (pd.DataFrame): DataFrame containing events data.\n",
    "    specific_date (datetime): Specific date for filtering.\n",
    "    duration (timedelta): Duration for filtering.\n",
    "\n",
    "    Returns:\n",
    "    filtered_df (pd.DataFrame): Filtered DataFrame.\n",
    "    unique_members_in_week (numpy.ndarray): Unique member IDs in the specified week.\n",
    "    \"\"\"\n",
    "\n",
    "    week_start = specific_date\n",
    "    week_end = week_start + timedelta(days=7)\n",
    "    members_in_week = events_data[(events_data['dt'] >= week_start) & (events_data['dt'] <= week_end)]['member_id']\n",
    "    filtered_df_backward = events_data[(events_data['dt'] >= (specific_date - duration)) & (events_data['dt'] < (week_start)) & (events_data['member_id'].isin(members_in_week))]\n",
    "    filtered_df_forward = events_data[(events_data['dt'] >= week_start) & (events_data['dt'] < week_end+timedelta(days=7)) & (events_data['member_id'].isin(members_in_week))]\n",
    "\n",
    "    return filtered_df_backward, filtered_df_forward, members_in_week\n",
    "\n",
    "def create_result_df(filtered_df, filtered_df_forward, unique_members):\n",
    "    \"\"\"\n",
    "    Create a DataFrame with event type counts for each member (create features).\n",
    "\n",
    "    Args:\n",
    "    filtered_df (pd.DataFrame): Filtered DataFrame.\n",
    "    unique_members (numpy.ndarray): Unique member IDs. (week forward)\n",
    "    event_types (list): List of event types.\n",
    "\n",
    "    Returns:\n",
    "    result_df (pd.DataFrame): DataFrame with event type counts.\n",
    "    \"\"\"\n",
    "    result_df = pd.DataFrame(index=unique_members)\n",
    "    event_types = ['personal_appointment_scheduled', 'sms_sent', 'chat_message_sent', 'usage']\n",
    "\n",
    "\n",
    "    for event_type in event_types:\n",
    "        event_count = filtered_df[filtered_df['event_type'] == event_type].groupby('member_id').size()\n",
    "        result_df[f'{event_type}_count'] = result_df.index.map(event_count).fillna(0)\n",
    "\n",
    "    result_df['average_usage_per_week'] = (result_df['usage_count'] / 12).astype(int)\n",
    "    \n",
    "    # Calculate sms_per_usage, handling zero in 'sms_sent_count'\n",
    "    result_df['sms_per_usage'] = (\n",
    "        result_df['usage_count'] / result_df['sms_sent_count'].replace({0: np.nan})\n",
    "    ).fillna(0).astype(int)\n",
    "\n",
    "    # Calculate personal_appointment_per_usage, handling zero in 'personal_appointment_scheduled_count'\n",
    "    result_df['personal_appointment_per_usage'] = (\n",
    "        result_df['usage_count'] / result_df['personal_appointment_scheduled_count'].replace({0: np.nan})\n",
    "    ).fillna(0).astype(int)\n",
    "\n",
    "    result_df.drop(columns=['usage_count'], inplace=True)\n",
    "    result_df.drop(columns=['sms_sent_count'], inplace=True)\n",
    "    result_df.drop(columns=['personal_appointment_scheduled_count'], inplace=True)\n",
    "    \n",
    "    # Aggregate 'gender' and 'age' columns\n",
    "    aggregated_info = filtered_df.groupby('member_id').agg({'gender': 'first', 'age': 'first'})\n",
    "\n",
    "    # Map 'gender' to numerical values (1 for 'male', 2 for 'female', 0 for 'unknown')\n",
    "    gender_mapping = {'M': 1, 'F': 2, 'unknown': 0}\n",
    "    aggregated_info['gender'] = aggregated_info['gender'].map(gender_mapping)\n",
    "\n",
    "    result_df = result_df.join(aggregated_info, how='left').fillna(0)\n",
    "\n",
    "    result_df.drop(columns=['age'], inplace=True)\n",
    "    result_df.drop(columns=['gender'], inplace=True)\n",
    "\n",
    "    # Calculate if a member had a pt_sale event in the last month or in the next 2 week (1 for yes, 0 for no)\n",
    "    pt_sale_count = filtered_df_forward[filtered_df_forward['event_type'] == 'pt_sale'].groupby('member_id').size()\n",
    "    pt_sale_count_before = filtered_df[filtered_df['event_type'] == 'pt_sale'].groupby('member_id').size()\n",
    "\n",
    "    result_df['pt_sale'] = ((result_df.index.map(pt_sale_count).fillna(0) > 0) | (result_df.index.map(pt_sale_count_before).fillna(0) > 0)).astype(int)\n",
    "\n",
    "    return result_df\n",
    "\n",
    "def train_and_evaluate_model_logistic_regression(result_df):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model and evaluate its performance.\n",
    "\n",
    "    Args:\n",
    "    result_df (pd.DataFrame): DataFrame with event type counts.\n",
    "\n",
    "    Returns:\n",
    "    model: Trained logistic regression model.\n",
    "    \"\"\"\n",
    "\n",
    "    X = result_df.drop(columns=['pt_sale'])\n",
    "    y = result_df['pt_sale']\n",
    "\n",
    "    # Manually split based on member IDs\n",
    "    ids = result_df.index.unique()\n",
    "    split = int(0.8 * len(ids))\n",
    "    train_ids, test_ids = ids[:split], ids[split:]\n",
    "\n",
    "    # Use boolean indexing to get training and testing sets\n",
    "    train_mask = result_df.index.isin(train_ids)\n",
    "    test_mask = result_df.index.isin(test_ids)\n",
    "\n",
    "    X_train = X[train_mask]\n",
    "    X_test = X[test_mask]\n",
    "    y_train = y[train_mask]\n",
    "    y_test = y[test_mask]\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "    # Normalized params:\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    # Choose a classification algorithm (Logistic Regression)\n",
    "    model = LogisticRegression(class_weight = 'balanced', C=0.01)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_normalized, y_train)\n",
    "    plot_feature_importance(model, X.columns)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred = model.predict(X_test_normalized)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_normalized)[:, 1])\n",
    "    # Calculate precision@k and recall@k\n",
    "    k = 10\n",
    "    precision_at_k_val = precision_at_k(y_test, model.predict_proba(X_test_normalized)[:, 1], k)\n",
    "    recall_at_k_val = recall_at_k(y_test, model.predict_proba(X_test_normalized)[:, 1], k)\n",
    "\n",
    "\n",
    "    # Plot diagnostic curves\n",
    "    plot_diagnostic_curves(model, X_test_normalized, y_test)\n",
    "\n",
    "    return model, accuracy, precision, recall, f1, roc_auc, precision_at_k_val, recall_at_k_val\n",
    "\n",
    "def train_and_evaluate_random_forest(result_df):\n",
    "    \"\"\"\n",
    "    Train a random forest model and evaluate its performance.\n",
    "\n",
    "    Args:\n",
    "    result_df (pd.DataFrame): DataFrame with event type counts.\n",
    "\n",
    "    Returns:\n",
    "    model: Trained random forest model.\n",
    "    accuracy, precision, recall, f1: Evaluation metrics.\n",
    "    \"\"\"\n",
    "    X = result_df.drop(columns=['pt_sale'])\n",
    "    y = result_df['pt_sale']\n",
    "\n",
    "    # Manually split based on member IDs\n",
    "    ids = result_df.index.unique()\n",
    "    split = int(0.8 * len(ids))\n",
    "    train_ids, test_ids = ids[:split], ids[split:]\n",
    "\n",
    "    # Use boolean indexing to get training and testing sets\n",
    "    train_mask = result_df.index.isin(train_ids)\n",
    "    test_mask = result_df.index.isin(test_ids)\n",
    "\n",
    "    X_train = X[train_mask]\n",
    "    X_test = X[test_mask]\n",
    "    y_train = y[train_mask]\n",
    "    y_test = y[test_mask]\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "    # Choose a classification algorithm (Random Forest)\n",
    "    model = RandomForestClassifier(class_weight='balanced_subsample', random_state=15)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    plot_feature_importance_random_forest(model, X.columns)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    # Calculate precision@k and recall@k\n",
    "    k = 10\n",
    "    precision_at_k_val = precision_at_k(y_test, model.predict_proba(X_test)[:, 1], k)\n",
    "    recall_at_k_val = recall_at_k(y_test, model.predict_proba(X_test)[:, 1], k)\n",
    "\n",
    "    # Plot diagnostic curves\n",
    "    plot_diagnostic_curves(model, X_test, y_test)\n",
    "\n",
    "    return model, accuracy, precision, recall, f1, roc_auc, precision_at_k_val, recall_at_k_val\n",
    "\n",
    "def precision_at_k(y_true, y_scores, k=10):\n",
    "    \"\"\"\n",
    "    Calculate precision at k.\n",
    "\n",
    "    Args:\n",
    "    y_true (array-like): True labels (1 for positive, 0 for negative).\n",
    "    y_scores (array-like): Predicted probabilities or scores.\n",
    "    k (int): Number of top predictions to consider.\n",
    "\n",
    "    Returns:\n",
    "    precision (float): Precision at k.\n",
    "    \"\"\"\n",
    "    # Sort predictions in descending order\n",
    "    sorted_indices = sorted(range(len(y_scores)), key=lambda i: y_scores[i], reverse=True)\n",
    "\n",
    "    # Select top k predictions\n",
    "    top_predictions = sorted_indices[:k]\n",
    "\n",
    "    # Calculate precision at k\n",
    "    true_positives = sum(y_true[i] for i in top_predictions)\n",
    "    precision = true_positives / k if k > 0 else 0.0\n",
    "\n",
    "    return precision\n",
    "\n",
    "def recall_at_k(y_true, y_scores, k=10):\n",
    "    \"\"\"\n",
    "    Calculate recall at k.\n",
    "\n",
    "    Args:\n",
    "    y_true (array-like): True labels (1 for positive, 0 for negative).\n",
    "    y_scores (array-like): Predicted probabilities or scores.\n",
    "    k (int): Number of top predictions to consider.\n",
    "\n",
    "    Returns:\n",
    "    recall (float): Recall at k.\n",
    "    \"\"\"\n",
    "    # Sort predictions in descending order\n",
    "    sorted_indices = sorted(range(len(y_scores)), key=lambda i: y_scores[i], reverse=True)\n",
    "\n",
    "    # Select top k predictions\n",
    "    top_predictions = sorted_indices[:k]\n",
    "\n",
    "    # Calculate recall at k\n",
    "    true_positives = sum(y_true[i] for i in top_predictions)\n",
    "    total_positives = sum(y_true)\n",
    "    recall = true_positives / total_positives if total_positives > 0 else 0.0\n",
    "\n",
    "    return recall\n",
    "\n",
    "def make_predictions(model, result_df_new, subscribers_data_new, date_to_predict):\n",
    "    \"\"\"\n",
    "    Make predictions for all individuals who have not taken personal training and have a subscription.\n",
    "\n",
    "    Args:\n",
    "    model: Trained logistic regression model.\n",
    "    result_df (pd.DataFrame): DataFrame with event type counts.\n",
    "    subscribers_data (pd.DataFrame): DataFrame containing subscribers data.\n",
    "    date_to_predict (datetime): Specific date for predictions.\n",
    "\n",
    "    Returns:\n",
    "    subscribers_data_for_date (pd.DataFrame): Subscribers data with predicted probabilities.\n",
    "    \"\"\"\n",
    "    prediction_df = result_df_new[result_df_new['pt_sale'] == 0].drop(columns=['pt_sale'])\n",
    "    subscribers_data_for_date = subscribers_data_new[subscribers_data_new['effective_date'] == date_to_predict]\n",
    "\n",
    "    # Filter prediction_df to include only rows with member_id present in subscribers_data_for_date\n",
    "    # prediction_df = prediction_df[prediction_df.index.isin(subscribers_data_for_date['member_id'])]\n",
    "\n",
    "    if not prediction_df.empty:\n",
    "        # Continue with the predictions\n",
    "        prediction_df['predicted_probability'] = model.predict_proba(prediction_df)[:, 1]\n",
    "\n",
    "        # Rank and recommend the top 10 individuals\n",
    "        top_10_recommendations = prediction_df.sort_values(by='predicted_probability', ascending=False).drop_duplicates().head(10)\n",
    "\n",
    "    else:\n",
    "        print(\"No predictions available for the selected date.\")\n",
    "\n",
    "    # Merge the DataFrames on 'member_id' to add 'predicted_probability' to 'subscribers_data_for_date'\n",
    "    subscribers_data_for_date = subscribers_data_for_date.merge(prediction_df[['predicted_probability']],\n",
    "                                                                left_on='member_id', right_index=True, how='left')\n",
    "\n",
    "    # Fill NaN values with None\n",
    "    subscribers_data_for_date['predicted_probability'] = subscribers_data_for_date['predicted_probability'].where(\n",
    "        subscribers_data_for_date['predicted_probability'].notna(), None)\n",
    "\n",
    "    return subscribers_data_for_date, top_10_recommendations[['predicted_probability']]\n",
    "\n",
    "def generate_top_10_by_segment(subscribers_data_for_date):\n",
    "    \"\"\"\n",
    "    Generate and print top 10 recommendations for each segment.\n",
    "\n",
    "    Args:\n",
    "    subscribers_data_for_date (pd.DataFrame): Subscribers data with predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    sorted_dataframe = subscribers_data_for_date.sort_values(by='predicted_probability', ascending=False)\n",
    "    top_10_by_segment = {}\n",
    "\n",
    "    for segment_code in sorted_dataframe['segment_code'].unique():\n",
    "        # Filter the DataFrame for the current segment_code and select the top 10 rows\n",
    "        top_10_for_segment = sorted_dataframe[\n",
    "            (sorted_dataframe['segment_code'] == segment_code) &\n",
    "            (sorted_dataframe['predicted_probability'].notna()) &\n",
    "            (sorted_dataframe['predicted_probability'] > 0.1)\n",
    "        ].drop_duplicates(subset=['member_id']).head(10)\n",
    "\n",
    "        # Store only the 'member_id' and 'predicted_probability' columns in the dictionary\n",
    "        top_10_by_segment[segment_code] = top_10_for_segment[['member_id', 'predicted_probability']]\n",
    "\n",
    "\n",
    "    # Print the top 10 members for each segment\n",
    "    for segment_code, top_10_for_segment in top_10_by_segment.items():\n",
    "        print(f\"Top 10 for segment {segment_code}:\\n{top_10_for_segment}\\n\")\n",
    "\n",
    "def check_success(member_id, date_to_predict, events_data):\n",
    "    \"\"\"\n",
    "    Check if a member has a \"pt_sale\" event in a week from the specific date.\n",
    "\n",
    "    Args:\n",
    "    member_id (int): Member ID to check.\n",
    "    specific_date (datetime): Specific date.\n",
    "    events_data (pd.DataFrame): DataFrame containing events data.\n",
    "\n",
    "    Returns:\n",
    "    success (bool): True if success, False otherwise.\n",
    "    \"\"\"\n",
    "    end_date = date_to_predict + timedelta(days=14)  # 2 weeks from the specific date\n",
    "    member_events = events_data[(events_data['member_id'] == member_id) & (events_data['event_type'] == 'pt_sale')]\n",
    "    success = any((member_events['dt'] >= date_to_predict) & (member_events['dt'] <= end_date))\n",
    "\n",
    "    return success\n",
    "\n",
    "def collect_results(events_data, subscribers_data, start_date_for_train, date_to_predict, duration_in_days = 90, weeks_to_train = 50, model_type=1):\n",
    "    \"\"\"\n",
    "    model_type : 1 = logistic regression, 2 = RandomForest\n",
    "    \"\"\"\n",
    "\n",
    "    combine_result_dt = []\n",
    "    for i in range(weeks_to_train): # all relevnt dates in events_data \n",
    "        date_to_collect = start_date_for_train + timedelta(days=6*i)\n",
    "        filtered_df, filtered_df_forward, unique_members_in_week = filter_events_by_date(events_data, date_to_collect, timedelta(days=duration_in_days))\n",
    "        result_df = create_result_df(filtered_df, filtered_df_forward, unique_members_in_week)\n",
    "        combine_result_dt.append(result_df)\n",
    "\n",
    "    combine_result_dt = pd.concat(combine_result_dt)\n",
    "    print(combine_result_dt['pt_sale'].value_counts())\n",
    "    \n",
    "    # Check for features that are always zero\n",
    "    zero_features = combine_result_dt.columns[combine_result_dt.sum() == 0]\n",
    "\n",
    "    # Print the zero features\n",
    "    if len(zero_features) > 0:\n",
    "        print(\"Features that always have a value of zero:\")\n",
    "        print(zero_features)\n",
    "        combine_result_dt = combine_result_dt.drop(columns=zero_features)\n",
    "    \n",
    "    if model_type==1:\n",
    "        model, accuracy, precision, recall, f1, roc_auc, precision_at_k, recall_at_k = train_and_evaluate_model_logistic_regression(combine_result_dt)\n",
    "    else:\n",
    "        model, accuracy, precision, recall, f1, roc_auc, precision_at_k, recall_at_k = train_and_evaluate_random_forest(combine_result_dt)\n",
    "\n",
    "    combine_result_dt_new = []\n",
    "    for i in range(4): \n",
    "        date_to_collect = date_to_predict + timedelta(days=6*i)\n",
    "        filtered_df_new, filtered_df_forward_new, unique_members_in_week_new = filter_events_by_date(events_data, date_to_collect, timedelta(days=duration_in_days))\n",
    "        result_df_new = create_result_df(filtered_df_new, filtered_df_forward_new, unique_members_in_week_new)\n",
    "        combine_result_dt_new.append(result_df_new)\n",
    "    combine_result_dt_new = pd.concat(combine_result_dt_new)\n",
    "\n",
    "    subscribers_data_for_date, top_10_predictions = make_predictions(model, combine_result_dt_new, subscribers_data, date_to_predict)\n",
    "\n",
    "    generate_top_10_by_segment(subscribers_data_for_date)\n",
    "\n",
    "    top_10_predictions['success'] = False\n",
    "    # Check success for each member in top 10 predictions\n",
    "    for idx in top_10_predictions.index:\n",
    "        top_10_predictions.loc[idx, 'success'] = check_success(idx, date_to_predict, events_data)\n",
    "\n",
    "    # print(top_10_predictions)\n",
    "    \n",
    "    results = {\n",
    "    'model': model,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'roc_auc': roc_auc,\n",
    "    'precision@k': precision_at_k ,\n",
    "    'recall@k': recall_at_k,\n",
    "    }\n",
    "\n",
    "    return results, model\n",
    "\n",
    "def plot_feature_importance(model, feature_names):\n",
    "    \"\"\"\n",
    "    Plot feature importance for a logistic regression model.\n",
    "\n",
    "    Args:\n",
    "    model: Trained logistic regression model.\n",
    "    feature_names (list): List of feature names.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    if not hasattr(model, 'coef_'):\n",
    "        print(\"Feature importances are not available for this model.\")\n",
    "        return\n",
    "\n",
    "    importances = model.coef_[0]\n",
    "    feature_importance = pd.DataFrame(list(zip(feature_names, importances)), columns=['Feature', 'Importance'])\n",
    "    feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "    plt.xlabel('Coefficient Magnitude')\n",
    "    plt.title('Feature Importance for Logistic Regression')\n",
    "    plt.show()\n",
    "\n",
    "def plot_feature_importance_random_forest(model, feature_names):\n",
    "    \"\"\"\n",
    "    Plot feature importance for a random forest model.\n",
    "\n",
    "    Args:\n",
    "    model: Trained random forest model.\n",
    "    feature_names (list): List of feature names.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    if not hasattr(model, 'feature_importances_'):\n",
    "        print(\"Feature importances are not available for this model.\")\n",
    "        return\n",
    "\n",
    "    importances = model.feature_importances_\n",
    "    feature_importance = pd.DataFrame(list(zip(feature_names, importances)), columns=['Feature', 'Importance'])\n",
    "    feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_importance['Feature'], feature_importance['Importance'])\n",
    "    plt.xlabel('Importance')\n",
    "    plt.title('Feature Importance for Random Forest')\n",
    "    plt.show()\n",
    "\n",
    "def plot_diagnostic_curves(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Plot diagnostic curves for a classification model.\n",
    "\n",
    "    Args:\n",
    "    model: Trained classification model.\n",
    "    X_test (pd.DataFrame): Test set features.\n",
    "    y_test (pd.Series): Test set labels.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Plot ROC curve\n",
    "    y_scores = model.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot precision-recall curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_scores)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "    plt.fill_between(recall, precision, step='post', alpha=0.2, color='b')\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title('Precision-Recall Curve')\n",
    "    plt.show()\n",
    "\n",
    "    # Calibration curve\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(y_test, y_scores, n_bins=10)\n",
    "    plt.plot(mean_predicted_value, fraction_of_positives, marker='o')\n",
    "    plt.title('Calibration Curve')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_date_for_train = datetime(2019, 6, 1) # start of relevant data to train\n",
    "    end_date_for_train = datetime(2021, 8, 21) # end of relevant data to train\n",
    "    # Calculate the difference between end_date_for_train and start_date_for_train\n",
    "    number_of_weeks = (end_date_for_train - start_date_for_train).days // 7\n",
    "\n",
    "    date_to_predict = datetime(2021, 1, 1) \n",
    "    events_data, subscribers_data = load_and_preprocess_data()\n",
    "    \n",
    "    results, model = collect_results(events_data, subscribers_data, start_date_for_train, date_to_predict, duration_in_days = 90, weeks_to_train = number_of_weeks, model_type=1)\n",
    "\n",
    "    for key, value in results.items():\n",
    "        print(\"------------------------\")\n",
    "        print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
