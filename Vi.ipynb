{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, f1_score, recall_score, roc_auc_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    Load events and subscribers data, drop unnecessary columns, and handle missing values.\n",
    "\n",
    "    Returns:\n",
    "    events_data (pd.DataFrame): DataFrame containing events data.\n",
    "    subscribers_data (pd.DataFrame): DataFrame containing subscribers data.\n",
    "    \"\"\"\n",
    "    events_data = pd.read_csv('data/events_data.csv')\n",
    "    subscribers_data = pd.read_csv('data/subscribers_data.csv')\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    subscribers_data = subscribers_data.drop(columns=['weeks_from_subscription_start'])\n",
    "\n",
    "    # Handle missing values\n",
    "    events_data.fillna(0, inplace=True)\n",
    "    subscribers_data.fillna(0, inplace=True)\n",
    "\n",
    "    # Convert date fields to datetime format\n",
    "    events_data['dt'] = pd.to_datetime(events_data['dt'])\n",
    "    subscribers_data['effective_date'] = pd.to_datetime(subscribers_data['effective_date'])\n",
    "\n",
    "    # Sort data by date\n",
    "    events_data.sort_values(by='dt', inplace=True)\n",
    "    subscribers_data.sort_values(by='effective_date', inplace=True)\n",
    "\n",
    "    return events_data, subscribers_data\n",
    "\n",
    "def filter_events_by_date(events_data, specific_date, duration):\n",
    "    \"\"\"\n",
    "    Filter events data based on a specific date and duration.\n",
    "\n",
    "    Args:\n",
    "    events_data (pd.DataFrame): DataFrame containing events data.\n",
    "    specific_date (datetime): Specific date for filtering.\n",
    "    duration (timedelta): Duration for filtering.\n",
    "\n",
    "    Returns:\n",
    "    filtered_df (pd.DataFrame): Filtered DataFrame.\n",
    "    unique_members_in_week (numpy.ndarray): Unique member IDs in the specified week.\n",
    "    \"\"\"\n",
    "\n",
    "    week_start = specific_date\n",
    "    week_end = week_start + timedelta(days=6)\n",
    "    members_in_week = events_data[(events_data['dt'] >= week_start) & (events_data['dt'] <= week_end)]['member_id']\n",
    "    filtered_df_backward = events_data[(events_data['dt'] >= (specific_date - duration)) & (events_data['dt'] < (week_start)) & (events_data['member_id'].isin(members_in_week))]\n",
    "    filtered_df_forward = events_data[(events_data['dt'] >= week_start) & (events_data['dt'] < (week_end)) & (events_data['member_id'].isin(members_in_week))]\n",
    "\n",
    "    return filtered_df_backward, filtered_df_forward, members_in_week\n",
    "\n",
    "\n",
    "def create_result_df(filtered_df, filtered_df_forward, unique_members, event_types):\n",
    "    \"\"\"\n",
    "    Create a DataFrame with event type counts for each member (create features).\n",
    "\n",
    "    Args:\n",
    "    filtered_df (pd.DataFrame): Filtered DataFrame.\n",
    "    unique_members (numpy.ndarray): Unique member IDs. (week forward)\n",
    "    event_types (list): List of event types.\n",
    "\n",
    "    Returns:\n",
    "    result_df (pd.DataFrame): DataFrame with event type counts.\n",
    "    \"\"\"\n",
    "    result_df = pd.DataFrame(index=unique_members)\n",
    "\n",
    "    for event_type in event_types:\n",
    "        event_count = filtered_df[filtered_df['event_type'] == event_type].groupby('member_id').size()\n",
    "        result_df[f'{event_type}_count'] = result_df.index.map(event_count).fillna(0)\n",
    "\n",
    "        # Count for the first, second, and third months\n",
    "        if event_type == 'usage':\n",
    "            for month in range(1, 4):\n",
    "                month_start = filtered_df['dt'].max() - timedelta(days=(month - 1) * 30)\n",
    "                month_end = filtered_df['dt'].max() - timedelta(days=month * 30)\n",
    "\n",
    "                event_count_month = filtered_df[\n",
    "                    (filtered_df['event_type'] == event_type) &\n",
    "                    (filtered_df['dt'] >= month_start) &\n",
    "                    (filtered_df['dt'] <= month_end)\n",
    "                ].groupby('member_id').size()\n",
    "\n",
    "                result_df[f'{event_type}_count_month_{month}'] = result_df.index.map(event_count_month).fillna(0)\n",
    "\n",
    "            # Calculate minimum and maximum intervals between usages\n",
    "            events_data_usage = filtered_df[filtered_df['event_type'] == 'usage'].copy()\n",
    "            events_data_usage.sort_values(by=['member_id', 'dt'], inplace=True)\n",
    "            events_data_usage['time_diff'] = events_data_usage.groupby('member_id')['dt'].diff().dt.days\n",
    "            min_interval = events_data_usage.groupby('member_id')['time_diff'].min().fillna(0).astype(int)\n",
    "            max_interval = events_data_usage.groupby('member_id')['time_diff'].max().fillna(0).astype(int)\n",
    "\n",
    "            # result_df['minimum_interval'] = result_df.index.map(min_interval).fillna(0)\n",
    "            # result_df['maximum_interval'] = result_df.index.map(max_interval).fillna(0)\n",
    "\n",
    "    # Calculate if a member had a pt_sale event in the next week (1 for yes, 0 for no)\n",
    "    pt_sale_count = filtered_df_forward[filtered_df_forward['event_type'] == 'pt_sale'].groupby('member_id').size()\n",
    "    result_df['pt_sale'] = (result_df.index.map(pt_sale_count).fillna(0) > 0).astype(int)\n",
    "    return result_df\n",
    "\n",
    "def train_and_evaluate_model(result_df):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model and evaluate its performance.\n",
    "\n",
    "    Args:\n",
    "    result_df (pd.DataFrame): DataFrame with event type counts.\n",
    "\n",
    "    Returns:\n",
    "    model: Trained logistic regression model.\n",
    "    \"\"\"\n",
    "\n",
    "    X = result_df.drop(columns=['pt_sale'])\n",
    "    y = result_df['pt_sale']\n",
    "\n",
    "    # Manually split based on member IDs\n",
    "    ids = result_df.index.unique()\n",
    "    split = int(0.8 * len(ids))\n",
    "    train_ids, test_ids = ids[:split], ids[split:]\n",
    "\n",
    "    # Use boolean indexing to get training and testing sets\n",
    "    train_mask = result_df.index.isin(train_ids)\n",
    "    test_mask = result_df.index.isin(test_ids)\n",
    "\n",
    "    X_train = X[train_mask]\n",
    "    X_test = X[test_mask]\n",
    "    y_train = y[train_mask]\n",
    "    y_test = y[test_mask]\n",
    "\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "    # Normalized params:\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    # Choose a classification algorithm (Logistic Regression)\n",
    "    # model = LogisticRegression(class_weight = 'balanced')\n",
    "    model = LogisticRegression()\n",
    "\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train_normalized, y_train)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred = model.predict(X_test_normalized)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test_normalized)[:, 1])\n",
    "\n",
    "    return model, accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "def train_and_evaluate_random_forest(result_df):\n",
    "    \"\"\"\n",
    "    Train a random forest model and evaluate its performance.\n",
    "\n",
    "    Args:\n",
    "    result_df (pd.DataFrame): DataFrame with event type counts.\n",
    "\n",
    "    Returns:\n",
    "    model: Trained random forest model.\n",
    "    accuracy, precision, recall, f1: Evaluation metrics.\n",
    "    \"\"\"\n",
    "    X = result_df.drop(columns=['pt_sale'])\n",
    "    y = result_df['pt_sale']\n",
    "\n",
    "    # Manually split based on member IDs\n",
    "    ids = result_df.index.unique()\n",
    "    split = int(0.8 * len(ids))\n",
    "    train_ids, test_ids = ids[:split], ids[split:]\n",
    "\n",
    "    # Use boolean indexing to get training and testing sets\n",
    "    train_mask = result_df.index.isin(train_ids)\n",
    "    test_mask = result_df.index.isin(test_ids)\n",
    "\n",
    "    X_train = X[train_mask]\n",
    "    X_test = X[test_mask]\n",
    "    y_train = y[train_mask]\n",
    "    y_test = y[test_mask]\n",
    "\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "    # Choose a classification algorithm (Random Forest)\n",
    "    model = RandomForestClassifier(class_weight='balanced_subsample', random_state=15)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on the testing set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate the model\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    return model, accuracy, precision, recall, f1, roc_auc\n",
    "\n",
    "def make_predictions(model, result_df, subscribers_data, date_to_predict):\n",
    "    \"\"\"\n",
    "    Make predictions for all individuals who have not taken personal training and have a subscription.\n",
    "\n",
    "    Args:\n",
    "    model: Trained logistic regression model.\n",
    "    result_df (pd.DataFrame): DataFrame with event type counts.\n",
    "    subscribers_data (pd.DataFrame): DataFrame containing subscribers data.\n",
    "    specific_date (datetime): Specific date for predictions.\n",
    "\n",
    "    Returns:\n",
    "    subscribers_data_for_date (pd.DataFrame): Subscribers data with predicted probabilities.\n",
    "    \"\"\"\n",
    "    prediction_df = result_df[result_df['pt_sale'] == 0].drop(columns=['pt_sale'])\n",
    "    subscribers_data_for_date = subscribers_data[subscribers_data['effective_date'] == date_to_predict]\n",
    "\n",
    "    # Filter prediction_df to include only rows with member_id present in subscribers_data_for_date\n",
    "    # prediction_df = prediction_df[prediction_df.index.isin(subscribers_data_for_date['member_id'])]\n",
    "\n",
    "    if not prediction_df.empty:\n",
    "        # Continue with the predictions\n",
    "        prediction_df['predicted_probability'] = model.predict_proba(prediction_df)[:, 1]\n",
    "\n",
    "        # Rank and recommend the top 10 individuals\n",
    "        top_10_recommendations = prediction_df.sort_values(by='predicted_probability', ascending=False).drop_duplicates().head(10)\n",
    "\n",
    "        # Print the top 10 recommendations\n",
    "        # print(\"top 10 recommendations:\", top_10_recommendations[['predicted_probability']])\n",
    "    else:\n",
    "        print(\"No predictions available for the selected date.\")\n",
    "\n",
    "    # Merge the DataFrames on 'member_id' to add 'predicted_probability' to 'subscribers_data_for_date'\n",
    "    subscribers_data_for_date = subscribers_data_for_date.merge(prediction_df[['predicted_probability']],\n",
    "                                                                left_on='member_id', right_index=True, how='left')\n",
    "\n",
    "    # Fill NaN values with None\n",
    "    subscribers_data_for_date['predicted_probability'] = subscribers_data_for_date['predicted_probability'].where(\n",
    "        subscribers_data_for_date['predicted_probability'].notna(), None)\n",
    "\n",
    "    return subscribers_data_for_date, top_10_recommendations[['predicted_probability']]\n",
    "\n",
    "def generate_top_10_by_segment(subscribers_data_for_date):\n",
    "    \"\"\"\n",
    "    Generate and print top 10 recommendations for each segment.\n",
    "\n",
    "    Args:\n",
    "    subscribers_data_for_date (pd.DataFrame): Subscribers data with predicted probabilities.\n",
    "    threshold (float): Threshold for considering predictions.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    sorted_dataframe = subscribers_data_for_date.sort_values(by='predicted_probability', ascending=False)\n",
    "    top_10_by_segment = {}\n",
    "\n",
    "    for segment_code in sorted_dataframe['segment_code'].unique():\n",
    "        # Filter the DataFrame for the current segment_code and select the top 10 rows\n",
    "        top_10_for_segment = sorted_dataframe[\n",
    "            (sorted_dataframe['segment_code'] == segment_code) &\n",
    "            (sorted_dataframe['predicted_probability'].notna()) &\n",
    "            (sorted_dataframe['predicted_probability']> 0.1)\n",
    "\n",
    "        ].drop_duplicates().head(10)\n",
    "\n",
    "        # Store only the 'member_id' and 'predicted_probability' columns in the dictionary\n",
    "        top_10_by_segment[segment_code] = top_10_for_segment[['member_id', 'predicted_probability']]\n",
    "\n",
    "    # Print the top 10 members for each segment\n",
    "    for segment_code, top_10_for_segment in top_10_by_segment.items():\n",
    "        print(f\"Top 10 for segment {segment_code}:\\n{top_10_for_segment}\\n\")\n",
    "\n",
    "\n",
    "def check_success(member_id, date_to_predict, events_data):\n",
    "    \"\"\"\n",
    "    Check if a member has a \"pt_sale\" event in a week from the specific date.\n",
    "\n",
    "    Args:\n",
    "    member_id (int): Member ID to check.\n",
    "    specific_date (datetime): Specific date.\n",
    "    events_data (pd.DataFrame): DataFrame containing events data.\n",
    "\n",
    "    Returns:\n",
    "    success (bool): True if success, False otherwise.\n",
    "    \"\"\"\n",
    "    end_date = date_to_predict + timedelta(days=7)  # One week from the specific date\n",
    "    member_events = events_data[(events_data['member_id'] == member_id) & (events_data['event_type'] == 'pt_sale')]\n",
    "    success = any((member_events['dt'] >= date_to_predict) & (member_events['dt'] <= end_date))\n",
    "    return success\n",
    "\n",
    "def collect_results(events_data, subscribers_data, start_date_for_train, date_to_predict ):\n",
    "\n",
    "    event_types = ['app_interaction', 'personal_appointment_scheduled', 'human_communication_event',\n",
    "                   'sms_sent', 'chat_message_sent', 'manual_email_sent', 'automated_email_sent',\n",
    "                   'fitness_consoltation', 'usage']\n",
    "\n",
    "    duration_in_days = 90  \n",
    "    \n",
    "    combine_result_dt = []\n",
    "\n",
    "    for i in range(375): # all relevnt dates in events_data \n",
    "        date_to_collect = start_date_for_train + timedelta(days=6*i)\n",
    "        filtered_df, filtered_df_forward, unique_members_in_week = filter_events_by_date(events_data, date_to_collect, timedelta(days=duration_in_days))\n",
    "        result_df = create_result_df(filtered_df, filtered_df_forward, unique_members_in_week, event_types)\n",
    "        combine_result_dt.append(result_df) \n",
    "\n",
    "    combine_result_dt = pd.concat(combine_result_dt)\n",
    "\n",
    "    model, accuracy, precision, recall, f1, roc_auc = train_and_evaluate_model(combine_result_dt)\n",
    "    # model, accuracy, precision, recall, f1, roc_auc = train_and_evaluate_random_forest(combine_result_dt)\n",
    "    subscribers_data_for_date, top_10_predictions = make_predictions(model, combine_result_dt, subscribers_data, date_to_predict)\n",
    "\n",
    "    generate_top_10_by_segment(subscribers_data_for_date)\n",
    "\n",
    "    top_10_predictions['success'] = False\n",
    "    # Check success for each member in top 10 predictions\n",
    "    for idx in top_10_predictions.index:\n",
    "        top_10_predictions.loc[idx, 'success'] = check_success(idx, date_to_predict, events_data)\n",
    "\n",
    "    top_10_true =  top_10_predictions['success'].sum()\n",
    "    \n",
    "    # Check all members that buy pt_sale:\n",
    "    members_in_week = events_data[(events_data['dt'] >= date_to_predict) & (events_data['dt'] <= (date_to_predict+timedelta(days=6)))]['member_id']\n",
    "    evente_week_forward = events_data[(events_data['dt'] >= date_to_predict) & (events_data['dt'] < (date_to_predict+timedelta(days=6))) & (events_data['member_id'].isin(members_in_week))]\n",
    "    # Calculate if a member had a pt_sale event in the next week (1 for yes, 0 for no)\n",
    "    all_possible_true = evente_week_forward[evente_week_forward['event_type'] == 'pt_sale'].groupby('member_id').size()\n",
    "    all_possible_true = (all_possible_true.index.map(all_possible_true).fillna(0) > 0).astype(int).sum()\n",
    "    \n",
    "    # Store relevant information for comparison\n",
    "    results = {\n",
    "    'model': model,\n",
    "    'accuracy': accuracy,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1,\n",
    "    'roc_auc': roc_auc,\n",
    "    'precision@k': top_10_true/10 ,\n",
    "    'recall@k': top_10_true/all_possible_true,\n",
    "    }\n",
    "\n",
    "    return results, model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_date_for_train = datetime(2015, 9, 11) # start of relevant data to train\n",
    "    date_to_predict = datetime(2021, 7, 9) \n",
    "    events_data, subscribers_data = load_and_preprocess_data()\n",
    "    results, model = collect_results(events_data, subscribers_data, start_date_for_train, date_to_predict)\n",
    "\n",
    "    for key, value in results.items():\n",
    "        print(\"------------------------\")\n",
    "        print(f\"{key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
